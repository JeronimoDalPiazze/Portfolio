# ğŸ›¢ï¸ Crude_Oil_Exports

End-to-end data engineering project to process and analyze Canadaâ€™s crude oil export data, built entirely with open-source tools and a modern ELT architecture.
---
## ğŸš€ Overview

This project demonstrates a complete **data engineering pipeline**, including:

1. **Ingestion** â†’ raw CSV files are placed manually in the `data/raw/` directory (automatic ingestion via Python + pandas planned for future versions)  
2. **Transformation** â†’ data cleaning, typing, and modeling using **dbt Core**  
3. **Storage** â†’ local **DuckDB** database  
4. **Orchestration** â†’ handled by **Prefect** (optional flow)  
5. **Visualization** â†’ interactive dashboards built in **Metabase**

The goal is to simulate a modern data-engineering workflow â€” from ingestion to visualization â€” using open-source technologies.
---
## ğŸ§© Tech Stack

| Stage | Tool | Purpose |
|-------|------|----------|
| Ingestion | Manual (future: Python + pandas) | Raw data placed in `data/raw/` |
| Storage | ğŸ¦† DuckDB | Local analytical database |
| Transformation | dbt Core | SQL-based modeling and testing |
| Orchestration | Prefect | Workflow automation |
| Visualization | Metabase | BI dashboards and data exploration |
---
## ğŸ§± Project Structure

```graphql
Crude_Oil_Exports/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                  # ğŸ—‚ï¸ Raw CSV data (manually placed)
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ dbt_project.yml       # Main dbt configuration
â”‚   â”œâ”€â”€ profiles/             # Connection settings
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ staging/          # Cleans and types raw data
â”‚       â””â”€â”€ marts/            # Analytical models ready for dashboards
â”œâ”€â”€ warehouse/                # ğŸ¦† DuckDB database file
â”œâ”€â”€ prefect/                  # âš™ï¸ Prefect orchestration flows
â”œâ”€â”€ metabase/                 # ğŸ“Š Dashboard configuration and Docker setup
â”œâ”€â”€ docs/                     # ğŸ“„ Technical documentation
â”œâ”€â”€ .env / .env.example       # Environment variables
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # This file
```
---
## âš™ï¸ How to Run Locally

```graphql
# 1. Clone the repository
git clone https://github.com/JeronimoDalPiazze/Portfolio.git
cd Portfolio/Crude_Oil_Exports

# 2. Create the virtual environment
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# 3. Create the .env file
cp .env.example .env

# 4. Place the raw CSV files in data/raw/
# (see expected file names in data/raw/README.md)

# 5. Run dbt
set -a; source .env; set +a
dbt build --project-dir dbt
```