# Data Engineering Portfolio â€“ Jeronimo Dal Piazze

## Crude Oil Exports â€“ Local ETL/ELT Pipeline
DuckDB | dbt Core | Prefect | Metabase | Python

## Overview
This project demonstrates a complete end-to-end data pipeline built entirely with free, lightweight, and local tools.
It automates the process of transforming raw CSV export data from NRCan (Natural Resources Canada) into a structured analytical model and visual dashboards.

The goal is to simulate a modern data-engineering workflow â€” from ingestion to visualization â€” using open-source technologies that can easily run on any laptop.

## Objectives
Centralize raw CSVs with version control and metadata for reproducibility.
Automate ingestion and loading of raw data into a lightweight analytical database (DuckDB).
Transform data into clean, modeled layers (staging â†’ marts) using dbt Core.
Orchestrate the pipeline using Prefect, enabling easy re-runs and monitoring.
Visualize insights through Metabase dashboards showing export trends, destinations, and products.

![alt text](image.png)

## Project Structure

```text
crude_oil_exports/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # ğŸ—‚ï¸ Raw CSV files (NRCan source data)
â”‚   â””â”€â”€ docs/                 # ğŸ“˜ Data dictionaries, metadata, and notes
â”‚
â”œâ”€â”€ warehouse/                # ğŸ¦† DuckDB database file (generated at runtime)
â”‚
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ dbt_project.yml       # Main dbt project configuration
â”‚   â”œâ”€â”€ profiles/             # Connection settings (DBT_PROFILES_DIR=./dbt/profiles)
â”‚   â”‚   â””â”€â”€ profiles.yml
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ staging/          # Clean and type the raw layer
â”‚       â”‚   â””â”€â”€ stg_exports.sql
â”‚       â”œâ”€â”€ marts/            # Build facts & dimensions for analysis
â”‚       â”‚   â””â”€â”€ fct_exports_monthly.sql
â”‚       â””â”€â”€ schema.yml        # dbt tests and documentation
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ ingest_csvs.py        # ğŸ Python script to load raw CSVs â†’ DuckDB (raw.exports)
â”‚
â”œâ”€â”€ prefect/
â”‚   â””â”€â”€ flow.py               # âš¡ Prefect flow orchestrating ingestion â†’ dbt transformations
â”‚
â”œâ”€â”€ metabase/
â”‚   â”œâ”€â”€ docker-compose.yml    # ğŸ“Š Launch Metabase locally (includes DuckDB connection)
â”‚   â”œâ”€â”€ README.md             # Connection setup guide
â”‚   â””â”€â”€ plugins/              # Folder for the DuckDB JDBC driver (.jar)
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture.md       # ğŸ§© Pipeline architecture and explanations
â”‚
â”œâ”€â”€ .env.example              # Environment variable examples
â”œâ”€â”€ .gitignore                # Ignore temporary, data, and environment files
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ Makefile                  # ğŸ”§ Predefined commands (ingest, dbt-run, flow, metabase-up)
â””â”€â”€ README.md                 # Main project documentation
```